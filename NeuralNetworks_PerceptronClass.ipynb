{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: Simulating a perceptron class\n",
    "\n",
    "In this project, we implement a **Perceptron** model â€” one of the simplest types of artificial neural networks â€” to solve a basic binary classification task. The perceptron, introduced by Frank Rosenblatt in 1958, is a foundational concept in machine learning that demonstrates how a model can learn to classify data points using a linear decision boundary.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The project includes the following key components:\n",
    "\n",
    "### 1. Perceptron Class\n",
    "The `Perceptron` class is implemented to:\n",
    "- Initialize the model with input dimensions and weights.\n",
    "- Compute the **weighted sum** of inputs using a linear combination of weights and features.\n",
    "- Apply an **activation function** to determine the output.\n",
    "- **Train** the perceptron using a basic weight update rule.\n",
    "\n",
    "### 2. Training Data\n",
    "We use a predefined dataset called `small_training_set`. The dataset consists of 2D input points and their corresponding binary target values (`1` or `-1`):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, num_inputs=2, weights=[1, 1]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = weights\n",
    "\n",
    "    def weighted_sum(self, inputs):\n",
    "        weighted_sum = 0\n",
    "        for i in range(self.num_inputs):\n",
    "            weighted_sum += self.weights[i] * inputs[i]\n",
    "        return weighted_sum\n",
    "\n",
    "    def activation(self, weighted_sum):\n",
    "        if weighted_sum >= 0:\n",
    "            return 1\n",
    "        if weighted_sum < 0:\n",
    "            return -1\n",
    "\n",
    "    def training(self, training_set):\n",
    "        foundLine = False\n",
    "        while not foundLine:\n",
    "            total_error = 0\n",
    "            for inputs in training_set:\n",
    "                prediction = self.activation(self.weighted_sum(inputs))\n",
    "                actual = training_set[inputs]\n",
    "                error = actual - prediction\n",
    "                total_error += abs(error)\n",
    "                for i in range(self.num_inputs):\n",
    "                    self.weights[i] += error * inputs[i]\n",
    "            if total_error == 0:\n",
    "                foundLine = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training a Perceptron instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10, 10]\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "small_training_set = {(0, 5): 1, (5, 0): -1, (0, -5): -1, (-5, 0): 1}\n",
    "\n",
    "# Initialize the Perceptron\n",
    "perceptron = Perceptron(num_inputs=2, weights=[0, 0])  # Initial weights set to 0 for training\n",
    "\n",
    "# Train on the training data\n",
    "perceptron.training(small_training_set)\n",
    "\n",
    "# Calculate weights\n",
    "perceptron_weights = perceptron.weights\n",
    "\n",
    "# Print the weights\n",
    "print(perceptron_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
